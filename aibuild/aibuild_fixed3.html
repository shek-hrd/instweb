<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>AI Web App Builder</title>
        <style>
            /* Modern, sleek styling */
            :root {
                --primary: #4361ee;
                --secondary: #3a0ca3;
                --accent: #4cc9f0;
                --light: #f8f9fa;
                --dark: #212529;
                --success: #4caf50;
                --warning: #ff9800;
                --danger: #f44336;
                --gray: #6c757d;
                --border-radius: 8px;
                --box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            }

            * {
                margin: 0;
                padding: 0;
                box-sizing: border-box;
            }

            body {
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background: linear-gradient(135deg, #f5f7fa 0%, #e4edf5 100%);
                color: var(--dark);
                min-height: 100vh;
                padding: 20px;
            }

            .container {
                max-width: 1400px;
                margin: 0 auto;
            }

            header {
                text-align: center;
                padding: 20px 0;
                margin-bottom: 20px;
            }

            h1 {
                color: var(--secondary);
                margin-bottom: 10px;
                font-size: 2.5rem;
            }

            .subtitle {
                color: var(--gray);
                font-size: 1.1rem;
            }

            .main-content {
                display: flex;
                gap: 20px;
                flex-wrap: wrap;
            }

            .panel {
                background: white;
                border-radius: var(--border-radius);
                box-shadow: var(--box-shadow);
                padding: 20px;
                flex: 1;
                min-width: 300px;
            }

            .panel-title {
                font-size: 1.4rem;
                margin-bottom: 15px;
                color: var(--secondary);
                display: flex;
                align-items: center;
                gap: 10px;
            }

            .panel-title i {
                color: var(--accent);
            }

            .input-section {
                flex: 1;
            }

            .controls {
                display: flex;
                flex-wrap: wrap;
                gap: 10px;
                margin-bottom: 15px;
            }

            .control-group {
                flex: 1;
                min-width: 200px;
            }

            label {
                display: block;
                margin-bottom: 5px;
                font-weight: 600;
                color: var(--dark);
            }

            textarea {
                width: 100%;
                height: 150px;
                padding: 12px;
                border: 1px solid #ddd;
                border-radius: var(--border-radius);
                resize: vertical;
                font-family: inherit;
                font-size: 1rem;
                transition: border-color 0.3s;
            }

            textarea:focus {
                outline: none;
                border-color: var(--accent);
                box-shadow: 0 0 0 2px rgba(76, 201, 240, 0.2);
            }

            select {
                width: 100%;
                padding: 10px;
                border: 1px solid #ddd;
                border-radius: var(--border-radius);
                background: white;
                font-family: inherit;
                font-size: 1rem;
            }

            button {
                background: var(--primary);
                color: white;
                border: none;
                padding: 12px 20px;
                border-radius: var(--border-radius);
                cursor: pointer;
                font-size: 1rem;
                font-weight: 600;
                transition: all 0.3s ease;
                display: flex;
                align-items: center;
                justify-content: center;
                gap: 8px;
            }

            button:hover {
                background: var(--secondary);
                transform: translateY(-2px);
                box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            }

            button:active {
                transform: translateY(0);
            }

            button:disabled {
                background: var(--gray);
                cursor: not-allowed;
                transform: none;
                box-shadow: none;
            }

            .btn-secondary {
                background: var(--gray);
            }

            .btn-secondary:hover {
                background: #5a6268;
            }

            .preview-section {
                display: flex;
                flex-direction: column;
            }

            #previewFrame {
                flex: 1;
                border: 1px solid #ddd;
                border-radius: var(--border-radius);
                background: white;
                min-height: 500px;
            }

            .status-container {
                margin-top: 15px;
                padding: 12px;
                border-radius: var(--border-radius);
                background: #e9f7fe;
                border-left: 4px solid var(--accent);
            }

            .status-message {
                display: flex;
                align-items: center;
                gap: 8px;
            }

            .spinner {
                width: 20px;
                height: 20px;
                border: 2px solid rgba(0, 0, 0, 0.1);
                border-left-color: var(--primary);
                border-radius: 50%;
                animation: spin 1s linear infinite;
            }

            @keyframes spin {
                to {
                    transform: rotate(360deg);
                }
            }

            .log-section {
                margin-top: 20px;
            }

            .log-entry {
                padding: 10px;
                margin-bottom: 8px;
                border-radius: var(--border-radius);
                background: #f8f9fa;
                border-left: 3px solid var(--accent);
                font-family: monospace;
                font-size: 0.9rem;
                overflow-x: auto;
            }

            .log-entry .prompt {
                border-left-color: var(--primary);
                background: #eef5ff;
            }

            .log-entry .response {
                border-left-color: var(--success);
                background: #f0fff4;
            }

            .log-entry .error {
                border-left-color: var(--danger);
                background: #ffebee;
            }

            .log-header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 10px;
            }

            .clear-btn {
                font-size: 0.9rem;
                padding: 6px 12px;
            }

            .progress-bar {
                height: 4px;
                background: #e0e0e0;
                border-radius: 2px;
                margin: 10px 0;
                overflow: hidden;
            }

            .progress-fill {
                height: 100%;
                background: var(--accent);
                width: 0%;
                transition: width 0.3s ease;
            }

            .model-info {
                background: #f0f8ff;
                padding: 10px;
                border-radius: var(--border-radius);
                margin-top: 10px;
                font-size: 0.9rem;
            }

            .model-info h4 {
                margin-bottom: 5px;
                color: var(--secondary);
            }

            .model-info p {
                margin: 3px 0;
                color: var(--gray);
            }

            @media (max-width: 768px) {
                .main-content {
                    flex-direction: column;
                }
                .controls {
                    flex-direction: column;
                }
            }
        </style>
    </head>
    <body>
        <div class="container">
            <header>
                <h1>Multi-AI Web App Builder</h1>
                <p class="subtitle">Describe your app and generate it with multiple AI models from various providers</p>
                <div id="aiStatus" style="margin-top: 10px; font-size: 0.9rem; color: var(--gray);">
                    <span id="statusText">Initializing AI services...</span>
                </div>
            </header>
            <div class="main-content">
                <!-- Input Panel -->
                <div class="panel input-section">
                    <h2 class="panel-title">üöÄ Create Your App</h2>
                    <div class="controls">
                        <div class="control-group">
                            <label for="appDescription">App Description</label>
                            <textarea id="appDescription" placeholder="Describe what kind of web application you want to create..."></textarea>
                        </div>
                    </div>
                    <div class="controls">
                        <div class="control-group">
                            <label for="modelSelect">AI Model</label>
                            <select id="modelSelect">
                                <optgroup label="üöÄ Code Supernova (1M Free)">
                                    <option value="code-supernova-free">Code Supernova 1M (Free)</option>
                                </optgroup>
                                <optgroup label="ü¶ô Meta Llama">
                                    <option value="llama-3.2-web">Llama 3.2 (Web, Free)</option>
                                </optgroup>
                                <optgroup label="ü§ñ OpenAI">
                                    <option value="gpt-4o-mini-web">GPT-4o Mini (Web, Free)</option>
                                    <option value="gpt-4o-free">OpenAI GPT-4o (Free Tier)</option>
                                </optgroup>
                                <optgroup label="üß† Anthropic Claude">
                                    <option value="claude-3.5-web">Claude 3.5 (Web, Free)</option>
                                    <option value="claude-sonnet-4">Claude Sonnet 4 (Balanced)</option>
                                    <option value="claude-opus-4">Claude Opus 4 (Most Intelligent)</option>
                                    <option value="anthropic-claude-free">Anthropic Claude (Free)</option>
                                </optgroup>
                                <optgroup label="üî• Google Gemini">
                                    <option value="gemini-puter">Google Gemini (Puter, Free)</option>
                                    <option value="gemini-free">Google Gemini (Free)</option>
                                </optgroup>
                                <optgroup label="ü§ó Hugging Face">
                                    <option value="huggingface-free">Hugging Face (Free)</option>
                                </optgroup>
                                <optgroup label="üåä Cohere">
                                    <option value="cohere-free">Cohere (Free)</option>
                                </optgroup>
                                <optgroup label="üå™Ô∏è Mistral">
                                    <option value="mistral-mini-free">Mistral Mini (Free)</option>
                                </optgroup>
                                <optgroup label="üÄÑ Qwen">
                                    <option value="qwen-coder-free">Qwen Coder (Free)</option>
                                </optgroup>
                                <optgroup label="üéØ Kimi">
                                    <option value="kimi-k2-free">Kimi K2 (Free)</option>
                                </optgroup>
                            </select>
                        </div>
                        <div class="control-group">
                            <label for="examples">Quick Examples</label>
                            <select id="examples">
                                <option value="">Select an example...</option>
                                <option value="A simple calculator with basic operations">Calculator</option>
                                <option value="A weather forecast app showing current conditions and 5-day forecast">Weather App</option>
                                <option value="A to-do list with add, delete, and mark complete functionality">Todo List</option>
                                <option value="A simple note-taking app with local storage">Note Taking</option>
                            </select>
                        </div>
                    </div>
                    <div class="controls">
                        <button id="generateBtn">
                            <span>Generate App</span>
                        </button>
                        <button id="clearLogBtn" class="btn-secondary clear-btn">Clear Log</button>
                    </div>
                    
                    <div class="model-info">
                        <h4>Model Information</h4>
                        <p><strong>üöÄ Code Supernova:</strong> 1 million free tokens for coding tasks</p>
                        <p><strong>ü¶ô Llama 3.2:</strong> Meta's open-source model via web interface</p>
                        <p><strong>ü§ñ GPT-4o Mini:</strong> OpenAI's efficient model for fast responses</p>
                        <p><strong>üß† Claude 3.5:</strong> Anthropic's latest model via web access</p>
                        <p><strong>üî• Google Gemini:</strong> Google's advanced AI via Puter integration</p>
                        <p><strong>ü§ó Hugging Face:</strong> Community models and inference APIs</p>
                        <p><strong>üåä Cohere:</strong> Enterprise-grade language models</p>
                        <p><strong>üå™Ô∏è Mistral:</strong> High-quality European AI models</p>
                        <p><strong>üÄÑ Qwen Coder:</strong> Specialized coding model from Alibaba</p>
                        <p><strong>üéØ Kimi K2:</strong> Advanced reasoning and coding capabilities</p>
                        <p><em>Note: Some models use placeholder API keys that need to be replaced with actual free tier keys for full functionality.</em></p>
                    </div>
</search_and_replace>
                    <div class="status-container">
                        <div class="status-message">
                            <span id="statusText">Ready to generate your app</span>
                        </div>
                        <div class="progress-bar">
                            <div class="progress-fill" id="progressFill"></div>
                        </div>
                    </div>
                </div>
                <!-- Preview Panel -->
                <div class="panel preview-section">
                    
                    <h2 class="panel-title">üì± Preview & Generated Code</h2>
</search_and_replace>
                    <iframe id="previewFrame" title="Generated App Preview"></iframe>
                    <div class="log-section">
                        <div class="log-header">
                            <h3>Generation Log</h3>
                        </div>
                        <div id="logContainer"></div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Include Puter.js library -->
        <script src="https://js.puter.com/v2/"></script>
        <script>
            // AI Service Management
            const aiServices = {};
            const availableModels = [];

            // DOM Elements
            const appDescriptionInput = document.getElementById('appDescription');
            const generateBtn = document.getElementById('generateBtn');
            const previewFrame = document.getElementById('previewFrame');
            const statusText = document.getElementById('statusText');
            const progressFill = document.getElementById('progressFill');
            const modelSelect = document.getElementById('modelSelect');
            const examplesSelect = document.getElementById('examples');
            const logContainer = document.getElementById('logContainer');
            const clearLogBtn = document.getElementById('clearLogBtn');
            const aiStatusText = document.getElementById('statusText');

            // Initialize logging array
            let logEntries = [];

            // Function to update the status message
            function updateStatus(message, isLoading = false) {
                statusText.textContent = message;
                // Add loading indicator if needed
                if (isLoading) {
                    statusText.innerHTML = `<span class="spinner"></span> ${message}`;
                } else {
                    statusText.innerHTML = message;
                }
            }

            // Function to update progress bar
            function updateProgress(percent) {
                progressFill.style.width = `${percent}%`;
            }

            // Function to add entry to log
            function addToLog(type, content) {
                const timestamp = new Date().toISOString();
                const entry = { timestamp, type, content };
                logEntries.push(entry);
                renderLog();
            }

            // Function to render log entries
            function renderLog() {
                logContainer.innerHTML = '';
                // Only show last 50 entries to keep performance good
                const recentEntries = logEntries.slice(-50);
                recentEntries.forEach(entry => {
                    const entryElement = document.createElement('div');
                    entryElement.className = `log-entry ${entry.type}`;
                    entryElement.innerHTML = `<strong>${new Date(entry.timestamp).toLocaleTimeString()}:</strong> ${entry.content}`;
                    logContainer.appendChild(entryElement);
                });
                // Scroll to bottom
                logContainer.scrollTop = logContainer.scrollHeight;
            }

            // Function to clear log
            function clearLog() {
                logEntries = [];
                renderLog();
            }

            // AI Service Testing Functions
            async function testAIService(modelKey, serviceName) {
                try {
                    const testPrompt = `Hello, please respond with just "OK" if you can hear me.`;

                    switch(modelKey) {
                        case 'claude-sonnet-4':
                        case 'claude-opus-4':
                            const response = await puter.ai.chat(testPrompt, { model: modelKey });
                            if (response && response.message && response.message.content) {
                                return true;
                            }
                            break;

                        case 'gemini-puter':
                            const geminiResponse = await puter.ai.chat(testPrompt, { model: 'gemini-pro' });
                            if (geminiResponse && geminiResponse.message && geminiResponse.message.content) {
                                return true;
                            }
                            break;

                        case 'code-supernova-free':
                            const supernovaResponse = await puter.ai.chat(testPrompt, { model: 'code-supernova-1-million' });
                            if (supernovaResponse && supernovaResponse.message && supernovaResponse.message.content) {
                                return true;
                            }
                            break;

                        default:
                            // For external APIs, we'll mark them as requiring API keys
                            return false;
                    }
                    return false;
                } catch (error) {
                    console.log(`${serviceName} test failed:`, error.message);
                    return false;
                }
            }

            // Initialize AI Services
            async function initializeAIServices() {
                aiStatusText.textContent = 'Testing AI services...';

                const servicesToTest = [
                    { key: 'claude-sonnet-4', name: 'Claude Sonnet 4', group: 'üß† Anthropic Claude' },
                    { key: 'claude-opus-4', name: 'Claude Opus 4', group: 'üß† Anthropic Claude' },
                    { key: 'gemini-puter', name: 'Google Gemini (Puter)', group: 'üî• Google Gemini' },
                    { key: 'code-supernova-free', name: 'Code Supernova', group: 'üöÄ Code Supernova (1M Free)' }
                ];

                let workingServices = 0;

                for (const service of servicesToTest) {
                    const isWorking = await testAIService(service.key, service.name);
                    aiServices[service.key] = {
                        name: service.name,
                        group: service.group,
                        working: isWorking,
                        requiresApiKey: !isWorking
                    };

                    if (isWorking) {
                        availableModels.push(service.key);
                        workingServices++;
                    }
                }

                // Update UI with available models
                updateModelSelect();

                if (workingServices > 0) {
                    aiStatusText.textContent = `Ready! ${workingServices} AI services available`;
                } else {
                    aiStatusText.textContent = 'No AI services available - some may require API keys';
                }
            }

            // Update model selection dropdown
            function updateModelSelect() {
                const currentValue = modelSelect.value;

                // Clear existing options
                while (modelSelect.children.length > 0) {
                    modelSelect.removeChild(modelSelect.children[0]);
                }

                // Add working models first
                availableModels.forEach(modelKey => {
                    const service = aiServices[modelKey];
                    if (service && service.working) {
                        const option = document.createElement('option');
                        option.value = modelKey;
                        option.textContent = `${service.group} - ${service.name}`;
                        modelSelect.appendChild(option);
                    }
                });

                // Add non-working models that require API keys
                Object.keys(aiServices).forEach(modelKey => {
                    const service = aiServices[modelKey];
                    if (service && !service.working) {
                        const option = document.createElement('option');
                        option.value = modelKey;
                        option.textContent = `${service.group} - ${service.name} (API Key Required)`;
                        option.disabled = true;
                        modelSelect.appendChild(option);
                    }
                });

                // Restore previous selection if still available
                if (currentValue && modelSelect.querySelector(`option[value="${currentValue}"]`)) {
                    modelSelect.value = currentValue;
                }
            }

            // API Key Management
            function showApiKeyDialog(serviceName, modelKey) {
                const apiKey = prompt(`Enter API key for ${serviceName}:\n\nThis key will be stored locally for this session only.`);
                if (apiKey && apiKey.trim()) {
                    localStorage.setItem(`apiKey_${modelKey}`, apiKey.trim());
                    return apiKey.trim();
                }
                return null;
            }

            // Get stored API key
            function getStoredApiKey(modelKey) {
                return localStorage.getItem(`apiKey_${modelKey}`);
            }

            // Function to generate the HTML code for the app
            async function generateAppCode(description, model, retryCount = 0) {
                // Add prompt to log
                addToLog('prompt', `Generating app with ${model}: ${description}`);

                // Define the prompt for all AI models
                const prompt = `Generate a complete, self-contained HTML file for a web application based on this description: "${description}". The output should be valid HTML code only, including embedded CSS and JavaScript if needed. Do not include any explanations or markdown formatting. Just the raw HTML code. Make sure it's a single HTML file that works when opened directly in a browser. The application should be visually appealing and functional. Ensure the generated code uses modern web standards. Please make the generated code as robust and clean as possible. The final code should be optimized for performance and user experience.`;

                
                try {
                    // Reset progress
                    updateProgress(0);
                    updateStatus('Initializing AI...', true);

                    let response;

                    // Check if model requires API key and get it
                    const service = aiServices[model];
                    if (service && service.requiresApiKey) {
                        let apiKey = getStoredApiKey(model);
                        if (!apiKey) {
                            apiKey = showApiKeyDialog(service.name, model);
                            if (!apiKey) {
                                throw new Error(`API key required for ${service.name}. Please provide a valid API key.`);
                            }
                        }
                    }
>>>>>>> REPLACE
</diff>
</search_and_replace>

                    // Route to appropriate AI service based on model selection
                    switch(model) {
                        case 'code-supernova-free':
                            response = await callCodeSupernova(prompt);
                            break;
                        case 'llama-3.2-web':
                            response = await callLlamaWeb(prompt);
                            break;
                        case 'gpt-4o-mini-web':
                            response = await callGPT4oMiniWeb(prompt);
                            break;
                        case 'claude-3.5-web':
                            response = await callClaudeWeb(prompt);
                            break;
                        case 'claude-sonnet-4':
                        case 'claude-opus-4':
                            response = await callPuterClaude(prompt, model);
                            break;
                        case 'anthropic-claude-free':
                            response = await callAnthropicClaude(prompt);
                            break;
                        case 'gemini-puter':
                            response = await callPuterGemini(prompt);
                            break;
                        case 'gemini-free':
                            response = await callGeminiFree(prompt);
                            break;
                        case 'huggingface-free':
                            response = await callHuggingFace(prompt);
                            break;
                        case 'cohere-free':
                            response = await callCohere(prompt);
                            break;
                        case 'mistral-mini-free':
                            response = await callMistral(prompt);
                            break;
                        case 'qwen-coder-free':
                            response = await callQwenCoder(prompt);
                            break;
                        case 'kimi-k2-free':
                            response = await callKimi(prompt);
                            break;
                        case 'gpt-4o-free':
                            response = await callOpenAIFree(prompt);
                            break;
                        default:
                            throw new Error(`Unsupported model: ${model}`);
                    }

                    // Add response to log
                    addToLog('response', `Generated ${response.length} characters of HTML`);
                    return response;

                } catch (error) {
                    console.error('Error generating app:', error);

                    // Try fallback to working AI if this is the first attempt and we have working alternatives
                    if (retryCount === 0 && availableModels.length > 1) {
                        const fallbackModels = availableModels.filter(m => m !== model);
                        if (fallbackModels.length > 0) {
                            const fallbackModel = fallbackModels[0];
                            addToLog('error', `Primary AI (${model}) failed, trying fallback: ${fallbackModel}`);
                            try {
                                return await generateAppCode(description, fallbackModel, retryCount + 1);
                            } catch (fallbackError) {
                                addToLog('error', `Fallback AI also failed: ${fallbackError.message}`);
                            }
                        }
                    }

                    const errorMsg = `Failed to generate app: ${error.message || 'Unknown error'}`;
                    addToLog('error', errorMsg);
                    throw new Error(errorMsg);
                }
            }

            // Code Supernova Integration
            async function callCodeSupernova(prompt) {
                updateStatus('Connecting to Code Supernova...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    // Use the internal code-supernova model
                    const response = await puter.ai.chat(prompt, {
                        model: 'code-supernova-1-million'
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (response && response.message && response.message.content) {
                        const content = Array.isArray(response.message.content)
                            ? response.message.content[0]?.text
                            : response.message.content;
                        return content || response.text || 'Error: No content received';
                    }
                    throw new Error('Invalid response format');
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Llama 3.2 Web Integration
            async function callLlamaWeb(prompt) {
                updateStatus('Connecting to Llama 3.2...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            model: 'llama3-8b-8192',
                            messages: [{ role: 'user', content: prompt }],
                            max_tokens: 2000,
                            temperature: 0.7
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.choices?.[0]?.message?.content || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // GPT-4o Mini Web Integration
            async function callGPT4oMiniWeb(prompt) {
                updateStatus('Connecting to GPT-4o Mini...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': 'Bearer gsk_xxx
                        },
                        body: JSON.stringify({
                            model: 'gpt-4o-mini',
                            messages: [{ role: 'user', content: prompt }],
                            max_tokens: 2000,
                            temperature: 0.7
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.choices?.[0]?.message?.content || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Claude 3.5 Web Integration
            async function callClaudeWeb(prompt) {
                updateStatus('Connecting to Claude 3.5...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://api.anthropic.com/v1/messages', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'x-api-key': 'sk-ant-api03-xxx', // Free access key
                            'anthropic-version': '2023-06-01'
                        },
                        body: JSON.stringify({
                            model: 'claude-3-5-sonnet-20241022',
                            max_tokens: 2000,
                            messages: [{ role: 'user', content: prompt }]
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.content?.[0]?.text || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Puter Claude Integration (existing)
            async function callPuterClaude(prompt, model) {
                updateStatus('Connecting to Claude via Puter...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await puter.ai.chat(prompt, { model: model });
                    clearInterval(interval);
                    updateProgress(100);

                    if (response && response.message && response.message.content && Array.isArray(response.message.content)) {
                        const content = response.message.content[0];
                        return content?.text || 'Error: No content received';
                    }
                    throw new Error('Invalid response format');
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Anthropic Claude Free Integration
            async function callAnthropicClaude(prompt) {
                updateStatus('Connecting to Anthropic Claude...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://api.anthropic.com/v1/messages', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'x-api-key': 'sk-ant-api03-xxx' // Free tier key
                        },
                        body: JSON.stringify({
                            model: 'claude-3-haiku-20240307',
                            max_tokens: 2000,
                            messages: [{ role: 'user', content: prompt }]
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.content?.[0]?.text || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Puter Gemini Integration
            async function callPuterGemini(prompt) {
                updateStatus('Connecting to Gemini via Puter...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await puter.ai.chat(prompt, { model: 'gemini-pro' });
                    clearInterval(interval);
                    updateProgress(100);

                    if (response && response.message && response.message.content && Array.isArray(response.message.content)) {
                        const content = response.message.content[0];
                        return content?.text || 'Error: No content received';
                    }
                    throw new Error('Invalid response format');
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Google Gemini Free Integration
            async function callGeminiFree(prompt) {
                updateStatus('Connecting to Google Gemini...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=YOUR_FREE_API_KEY`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            contents: [{
                                parts: [{
                                    text: prompt
                                }]
                            }]
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.candidates?.[0]?.content?.parts?.[0]?.text || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Hugging Face Integration
            async function callHuggingFace(prompt) {
                updateStatus('Connecting to Hugging Face...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium', {
                        method: 'POST',
                        headers: {
                            'Authorization': 'Bearer hf_xxx', // Free inference API
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            inputs: prompt,
                            parameters: {
                                max_length: 2000,
                                temperature: 0.7
                            }
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return Array.isArray(data) ? data[0]?.generated_text || 'Error: No content received' : 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Cohere Integration
            async function callCohere(prompt) {
                updateStatus('Connecting to Cohere...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://api.cohere.ai/v1/generate', {
                        method: 'POST',
                        headers: {
                            'Authorization': 'Bearer xxx', // Free tier key
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            model: 'command',
                            prompt: prompt,
                            max_tokens: 2000,
                            temperature: 0.7
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.generations?.[0]?.text || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Mistral Integration
            async function callMistral(prompt) {
                updateStatus('Connecting to Mistral...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://api.mistral.ai/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': 'Bearer xxx' // Free tier key
                        },
                        body: JSON.stringify({
                            model: 'mistral-tiny',
                            messages: [{ role: 'user', content: prompt }],
                            max_tokens: 2000,
                            temperature: 0.7
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.choices?.[0]?.message?.content || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Qwen Coder Integration
            async function callQwenCoder(prompt) {
                updateStatus('Connecting to Qwen Coder...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://dashscope.aliyuncs.com/api/v1/services/audio/asr/asr-1', {
                        method: 'POST',
                        headers: {
                            'Authorization': 'Bearer xxx', // Free tier key
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            model: 'qwen-turbo',
                            input: {
                                messages: [{ role: 'user', content: prompt }]
                            },
                            parameters: {
                                max_tokens: 2000,
                                temperature: 0.7
                            }
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.output?.text || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Kimi K2 Integration
            async function callKimi(prompt) {
                updateStatus('Connecting to Kimi K2...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://api.moonshot.cn/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': 'Bearer xxx' // Free tier key
                        },
                        body: JSON.stringify({
                            model: 'moonshot-v1-8k',
                            messages: [{ role: 'user', content: prompt }],
                            max_tokens: 2000,
                            temperature: 0.7
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.choices?.[0]?.message?.content || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // OpenAI GPT-4o Free Integration
            async function callOpenAIFree(prompt) {
                updateStatus('Connecting to OpenAI GPT-4o...', true);
                let progress = 0;
                const interval = setInterval(() => {
                    progress += Math.random() * 15;
                    if (progress > 90) progress = 90;
                    updateProgress(progress);
                }, 300);

                try {
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': 'Bearer sk-xxx' // Free tier key
                        },
                        body: JSON.stringify({
                            model: 'gpt-4o',
                            messages: [{ role: 'user', content: prompt }],
                            max_tokens: 2000,
                            temperature: 0.7
                        })
                    });

                    clearInterval(interval);
                    updateProgress(100);

                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }

                    const data = await response.json();
                    return data.choices?.[0]?.message?.content || 'Error: No content received';
                } catch (error) {
                    clearInterval(interval);
                    updateProgress(0);
                    throw error;
                }
            }

            // Function to load the generated HTML into the iframe
            function loadPreview(htmlContent) {
                // Create a blob from the HTML string
                const blob = new Blob([htmlContent], { type: 'text/html;charset=utf-8' });
                // Create an object URL for the blob
                const url = URL.createObjectURL(blob);
                // Set the iframe's source to the blob URL
                previewFrame.src = url;
                // Add to log
                addToLog('response', 'Preview loaded');
            }

            // Event listener for the generate button
            generateBtn.addEventListener('click', async () => {
                const description = appDescriptionInput.value.trim();
                const model = modelSelect.value;
                // Validate input
                if (!description) {
                    updateStatus('Please enter a description for your app.', false);
                    addToLog('error', 'No description provided');
                    return;
                }
                // Disable button during processing
                generateBtn.disabled = true;
                generateBtn.innerHTML = '<span class="spinner"></span> Generating...';
                try {
                    // Generate the HTML code
                    const htmlCode = await generateAppCode(description, model);
                    // Load the generated code into the preview iframe
                    loadPreview(htmlCode);
                    // Update status to success
                    updateStatus('App generated successfully!', false);
                } catch (error) {
                    // Handle errors during generation
                    updateStatus(`Error: ${error.message}`, false);
                } finally {
                    // Re-enable button
                    generateBtn.disabled = false;
                    generateBtn.innerHTML = '<span>Generate App</span>';
                }
            });

            // Event listener for example selection
            examplesSelect.addEventListener('change', () => {
                const selectedExample = examplesSelect.value;
                if (selectedExample) {
                    appDescriptionInput.value = selectedExample;
                    examplesSelect.value = ''; // Reset selection
                }
            });

            // Event listener for clear log button
            clearLogBtn.addEventListener('click', clearLog);

            // Initialize AI services and setup
            window.addEventListener('load', async () => {
                // Initialize AI services first
                await initializeAIServices();

                // Pre-fill the input with an example description
                appDescriptionInput.value = "A simple todo list app with add, delete, and mark complete functionality.";
                // Add initial log entry
                addToLog('prompt', 'Page loaded - ready to generate apps');
            });
        </script>
    </body>
</html>
